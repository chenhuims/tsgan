{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoppelGANger\n",
    "\n",
    "## Method Overview\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "Assume a dataset can be modeled as $\\mathcal{D} = \\{ O^1 , O^2, ..., O^n\\}$ where $O^i$ is an object representing an atomic, high-dimensional data element, i.e., the combination of a single time series with its associated metadata. More precisely, each object $O^i = (A^i, R^i)$ contains $m$ *attributes* $A^i = [A_1^i, A_2^i, ..., A_m^i]$. For example, attribute $A_j^i$ could represent user $i$'s physical location. Note that this model can support datasets in which multiple objects have the same set of attributes. \n",
    "\n",
    "The second component of each object is a time series of *records* $R^i = [R_1^i, R_2^i, ..., R_{T^i}^i]$. For example, in retail, the time series may contain the numbers of products that user $i$ purchases on a given day. Different objects may contain different numbers of records (i.e., time series of different lengths). The number of records in object $O^i$ is given by $T^i$. Each record $R_j^i = (t_j^i, f_j^i)$ contains a *timestamp* $t_j^i$ and $K$ features $f_j^i = [f_{j, 1}^i, f_{j, 2}^i, ..., f_{j, 1K^i}]$ (e.g., the number of each product among all $K$ products that the user purchases). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gan.output import OutputType, Normalization, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<output.Output at 0x7f9bac33c0b8>, <output.Output at 0x7f9bac33c320>]"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "sys.path.append(\"./gan\")\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"..\", \"data\", \"FCC_MBA\", \"data_feature_output.pkl\")\n",
    "\n",
    "with open(os.path.join(file_path), \"rb\") as f:\n",
    "    data_feature_outputs = pickle.load(f)\n",
    "\n",
    "data_feature_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'dim': 1,\n 'is_gen_flag': False,\n 'normalization': <Normalization.ZERO_ONE: 'ZERO_ONE'>,\n 'type_': <OutputType.CONTINUOUS: 'CONTINUOUS'>}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data_feature_outputs[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'dim': 1,\n 'is_gen_flag': False,\n 'normalization': <Normalization.ZERO_ONE: 'ZERO_ONE'>,\n 'type_': <OutputType.CONTINUOUS: 'CONTINUOUS'>}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data_feature_outputs[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<output.Output at 0x7f9ba5bb42e8>,\n <output.Output at 0x7f9bac33c6a0>,\n <output.Output at 0x7f9bac33c710>]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "file_path = os.path.join(\"..\", \"data\", \"FCC_MBA\", \"data_attribute_output.pkl\")\n",
    "\n",
    "with open(os.path.join(file_path), \"rb\") as f:\n",
    "    data_attribute_outputs = pickle.load(f)\n",
    "\n",
    "data_attribute_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'dim': 15,\n 'is_gen_flag': False,\n 'normalization': None,\n 'type_': <OutputType.DISCRETE: 'DISCRETE'>}"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data_attribute_outputs[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'dim': 5,\n 'is_gen_flag': False,\n 'normalization': None,\n 'type_': <OutputType.DISCRETE: 'DISCRETE'>}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data_attribute_outputs[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'dim': 53,\n 'is_gen_flag': False,\n 'normalization': None,\n 'type_': <OutputType.DISCRETE: 'DISCRETE'>}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data_attribute_outputs[2].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'_files': ['data_feature_max.npy',\n  'data_feature.npy',\n  'data_attribute.npy',\n  'data_gen_flag.npy',\n  'data_feature_min.npy'],\n 'allow_pickle': False,\n 'f': <numpy.lib.npyio.BagObj at 0x7f9bac32ff98>,\n 'fid': <_io.BufferedReader name='../data/FCC_MBA/data_train.npz'>,\n 'files': ['data_feature_max',\n  'data_feature',\n  'data_attribute',\n  'data_gen_flag',\n  'data_feature_min'],\n 'pickle_kwargs': {'encoding': 'ASCII', 'fix_imports': True},\n 'zip': <zipfile.ZipFile file=<_io.BufferedReader name='../data/FCC_MBA/data_train.npz'> mode='r'>}"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data_npz = np.load(os.path.join(\"..\", \"data\", \"FCC_MBA\", \"data_train.npz\"))\n",
    "data_npz.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       ...,\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.]])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data_npz[\"data_gen_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(600, 56)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data_npz[\"data_gen_flag\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data_npz[\"data_attribute\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(600, 73)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data_npz[\"data_attribute\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[0.00190305, 0.        ],\n        [0.00542065, 0.        ],\n        [0.00351279, 0.        ],\n        ...,\n        [0.00570855, 0.        ],\n        [0.0109244 , 0.        ],\n        [0.01260134, 0.        ]],\n\n       [[0.00451891, 0.        ],\n        [0.01619207, 0.        ],\n        [0.00240422, 0.        ],\n        ...,\n        [0.00979518, 0.        ],\n        [0.00285562, 0.        ],\n        [0.00412524, 0.        ]],\n\n       [[0.00871978, 0.        ],\n        [0.06614204, 0.        ],\n        [0.00705297, 0.        ],\n        ...,\n        [0.01537887, 0.        ],\n        [0.0196006 , 0.        ],\n        [0.02046846, 0.        ]],\n\n       ...,\n\n       [[0.05727319, 0.        ],\n        [0.04847331, 0.        ],\n        [0.02320519, 0.        ],\n        ...,\n        [0.06335463, 0.        ],\n        [0.0498604 , 0.        ],\n        [0.04445172, 0.        ]],\n\n       [[0.10847276, 0.        ],\n        [0.0983321 , 0.        ],\n        [0.03953493, 0.        ],\n        ...,\n        [0.05072008, 0.        ],\n        [0.0216756 , 0.        ],\n        [0.02107071, 0.        ]],\n\n       [[0.12601896, 0.        ],\n        [0.1551092 , 0.        ],\n        [0.1508659 , 0.        ],\n        ...,\n        [0.15091276, 0.        ],\n        [0.14953195, 0.        ],\n        [0.1553389 , 0.        ]]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data_npz[\"data_feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(600, 56, 2)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data_npz[\"data_feature\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Orange Juice data, the features include sales, price, as well as deal and advertisement information; while the attributes contain store ID and brand ID.  \n",
    "\n",
    "| Attributes | Description | Possible Values |\n",
    "| --- | --- | --- |\n",
    "| store | Store ID | integers |\n",
    "| brand | Brand/Product ID | integers |\n",
    "\n",
    "| Features | Description | Possible Values |\n",
    "| --- | --- | --- |\n",
    "| sales | Number of products sold | integers |\n",
    "| price | Price of the product | float numbers |\n",
    "| deal | Deal information | float numbers |\n",
    "| feat | Advertisement information | float numbers |\n",
    "\n",
    "| Timestamp Description | Possible Values |\n",
    "| --- | --- |\n",
    "| The starting date of each week | 1990-01-07 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'type_': <OutputType.DISCRETE: 'DISCRETE'>, 'normalization': None, 'is_gen_flag': False, 'dim': 83}\n{'type_': <OutputType.DISCRETE: 'DISCRETE'>, 'normalization': None, 'is_gen_flag': False, 'dim': 11}\n"
    }
   ],
   "source": [
    "ojdata_attribute_outputs = []\n",
    "# store ID attribute\n",
    "ojdata_attribute_outputs.append(Output(OutputType.DISCRETE, 83, None))\n",
    "# brand ID attribute\n",
    "ojdata_attribute_outputs.append(Output(OutputType.DISCRETE, 11, None))\n",
    "\n",
    "print(ojdata_attribute_outputs[0].__dict__)\n",
    "print(ojdata_attribute_outputs[1].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/ojdata/data_attribute_output.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ojdata_attribute_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<gan.output.Output at 0x7f9bac33cda0>, <gan.output.Output at 0x7f9bac33cfd0>]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "with open(\"../data/ojdata/data_attribute_output.pkl\", \"rb\") as f:\n",
    "    data_attribute_outputs = pickle.load(f)\n",
    "\n",
    "data_attribute_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ojdata_feature_outputs = []\n",
    "# sales feature\n",
    "ojdata_feature_outputs.append(Output(OutputType.CONTINUOUS, 1, Normalization.ZERO_ONE))\n",
    "# price feature\n",
    "ojdata_feature_outputs.append(Output(OutputType.CONTINUOUS, 1, Normalization.ZERO_ONE))\n",
    "# deal feature\n",
    "ojdata_feature_outputs.append(Output(OutputType.CONTINUOUS, 1, Normalization.ZERO_ONE))\n",
    "# feat feature\n",
    "ojdata_feature_outputs.append(Output(OutputType.CONTINUOUS, 1, Normalization.ZERO_ONE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'type_': <OutputType.CONTINUOUS: 'CONTINUOUS'>, 'normalization': <Normalization.ZERO_ONE: 'ZERO_ONE'>, 'is_gen_flag': False, 'dim': 1}\n{'type_': <OutputType.CONTINUOUS: 'CONTINUOUS'>, 'normalization': <Normalization.ZERO_ONE: 'ZERO_ONE'>, 'is_gen_flag': False, 'dim': 1}\n{'type_': <OutputType.CONTINUOUS: 'CONTINUOUS'>, 'normalization': <Normalization.ZERO_ONE: 'ZERO_ONE'>, 'is_gen_flag': False, 'dim': 1}\n{'type_': <OutputType.CONTINUOUS: 'CONTINUOUS'>, 'normalization': <Normalization.ZERO_ONE: 'ZERO_ONE'>, 'is_gen_flag': False, 'dim': 1}\n"
    }
   ],
   "source": [
    "print(ojdata_feature_outputs[0].__dict__)\n",
    "print(ojdata_feature_outputs[1].__dict__)\n",
    "print(ojdata_feature_outputs[2].__dict__)\n",
    "print(ojdata_feature_outputs[3].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/ojdata/data_feature_output.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ojdata_feature_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<gan.output.Output at 0x7f9bac357128>,\n <gan.output.Output at 0x7f9bac3572e8>,\n <gan.output.Output at 0x7f9bac357208>,\n <gan.output.Output at 0x7f9bac357198>]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "with open(\"../data/ojdata/data_feature_output.pkl\", \"rb\") as f:\n",
    "    data_feature_outputs = pickle.load(f)\n",
    "\n",
    "data_feature_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Data\n",
    "\n",
    "Next, we create a dictionary called `data_npz` which include the following three numpy arrays `data_feature`, `data_attribute`, and `data_gen_flag`. \n",
    "\n",
    "* `data_feature`: Training features, in numpy float32 array format. The size is `[(number of training samples) x (maximum length) x (total dimension of features)]`. Categorical features are stored by one-hot encoding; for example, if a categorical feature has 3 possibilities, then it can take values between `[1., 0., 0.]`, `[0., 1., 0.]`, and `[0., 0., 1.]`. Each continuous feature should be normalized to `[0, 1]` or `[-1, 1]`. The array is padded by zeros after the time series ends.\n",
    "\n",
    "* `data_attribute`: Training attributes, in numpy float32 array format. The size is `[(number of training samples) x (total dimension of attributes)]`. Categorical attributes are stored by one-hot encoding; for example, if a categorical attribute has 3 possibilities, then it can take values between `[1., 0., 0.]`, `[0., 1., 0.]`, and `[0., 0., 1.]`. Each continuous attribute should be normalized to `[0, 1]` or `[-1, 1]`.\n",
    "\n",
    "* data_gen_flag: Flags indicating the activation of features, in numpy float32 array format. The size is `[(number of training samples) x (maximum length)]`. 1 means the time series is activated at this time step, 0 means the time series is inactivated at this timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   store  brand  week   logmove  constant    price1    price2    price3  \\\n0      2      1    40  9.018695         1  0.060469  0.060497  0.042031   \n1      2      1    46  8.723231         1  0.060469  0.060312  0.045156   \n2      2      1    47  8.253228         1  0.060469  0.060312  0.045156   \n3      2      1    48  8.987197         1  0.060469  0.060312  0.049844   \n4      2      1    50  9.093357         1  0.060469  0.060312  0.043594   \n\n     price4    price5    price6    price7    price8    price9   price10  \\\n0  0.029531  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844   \n1  0.046719  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031   \n2  0.046719  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656   \n3  0.037344  0.049531  0.053021  0.045781  0.041406  0.042344  0.032656   \n4  0.031094  0.049531  0.053021  0.046648  0.041406  0.042344  0.032656   \n\n    price11  deal  feat     profit  \n0  0.038984     1   0.0  37.992326  \n1  0.038984     0   0.0  30.126667  \n2  0.038984     0   0.0  30.000000  \n3  0.038984     0   0.0  29.950000  \n4  0.038203     0   0.0  29.920000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store</th>\n      <th>brand</th>\n      <th>week</th>\n      <th>logmove</th>\n      <th>constant</th>\n      <th>price1</th>\n      <th>price2</th>\n      <th>price3</th>\n      <th>price4</th>\n      <th>price5</th>\n      <th>price6</th>\n      <th>price7</th>\n      <th>price8</th>\n      <th>price9</th>\n      <th>price10</th>\n      <th>price11</th>\n      <th>deal</th>\n      <th>feat</th>\n      <th>profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>40</td>\n      <td>9.018695</td>\n      <td>1</td>\n      <td>0.060469</td>\n      <td>0.060497</td>\n      <td>0.042031</td>\n      <td>0.029531</td>\n      <td>0.049531</td>\n      <td>0.053021</td>\n      <td>0.038906</td>\n      <td>0.041406</td>\n      <td>0.028906</td>\n      <td>0.024844</td>\n      <td>0.038984</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>37.992326</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>46</td>\n      <td>8.723231</td>\n      <td>1</td>\n      <td>0.060469</td>\n      <td>0.060312</td>\n      <td>0.045156</td>\n      <td>0.046719</td>\n      <td>0.049531</td>\n      <td>0.047813</td>\n      <td>0.045781</td>\n      <td>0.027969</td>\n      <td>0.042969</td>\n      <td>0.042031</td>\n      <td>0.038984</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>30.126667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>47</td>\n      <td>8.253228</td>\n      <td>1</td>\n      <td>0.060469</td>\n      <td>0.060312</td>\n      <td>0.045156</td>\n      <td>0.046719</td>\n      <td>0.037344</td>\n      <td>0.053021</td>\n      <td>0.045781</td>\n      <td>0.041406</td>\n      <td>0.048125</td>\n      <td>0.032656</td>\n      <td>0.038984</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>1</td>\n      <td>48</td>\n      <td>8.987197</td>\n      <td>1</td>\n      <td>0.060469</td>\n      <td>0.060312</td>\n      <td>0.049844</td>\n      <td>0.037344</td>\n      <td>0.049531</td>\n      <td>0.053021</td>\n      <td>0.045781</td>\n      <td>0.041406</td>\n      <td>0.042344</td>\n      <td>0.032656</td>\n      <td>0.038984</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>29.950000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>1</td>\n      <td>50</td>\n      <td>9.093357</td>\n      <td>1</td>\n      <td>0.060469</td>\n      <td>0.060312</td>\n      <td>0.043594</td>\n      <td>0.031094</td>\n      <td>0.049531</td>\n      <td>0.053021</td>\n      <td>0.046648</td>\n      <td>0.041406</td>\n      <td>0.042344</td>\n      <td>0.032656</td>\n      <td>0.038203</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>29.920000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "original_sales = pd.read_csv(\"../data/ojdata/yx.csv\")\n",
    "original_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "913\n"
    }
   ],
   "source": [
    "# Check number of time series in the data\n",
    "n_ts_samples = len(original_sales.groupby([\"store\", \"brand\"]).groups.keys())\n",
    "print(n_ts_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Minmum week number is  40\nMaximum week number is  160\nMaximum time series length  120\n"
    }
   ],
   "source": [
    "# Get the maximum length of the time series\n",
    "min_week = original_sales[\"week\"].min()\n",
    "max_week = original_sales[\"week\"].max()\n",
    "print(\"Minmum week number is \", min_week)\n",
    "print(\"Maximum week number is \", max_week)\n",
    "max_ts_length = max_week - min_week\n",
    "print(\"Maximum time series length \", max_ts_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'_files': ['data_feature_max.npy',\n  'data_feature.npy',\n  'data_attribute.npy',\n  'data_gen_flag.npy',\n  'data_feature_min.npy'],\n 'allow_pickle': False,\n 'f': <numpy.lib.npyio.BagObj at 0x7f9bb0b2feb8>,\n 'fid': <_io.BufferedReader name='../data/FCC_MBA/data_train.npz'>,\n 'files': ['data_feature_max',\n  'data_feature',\n  'data_attribute',\n  'data_gen_flag',\n  'data_feature_min'],\n 'pickle_kwargs': {'encoding': 'ASCII', 'fix_imports': True},\n 'zip': <zipfile.ZipFile file=<_io.BufferedReader name='../data/FCC_MBA/data_train.npz'> mode='r'>}"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "data_npz = np.load(os.path.join(\"..\", \"data\", \"FCC_MBA\", \"data_train.npz\"))\n",
    "data_npz.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2079777.,       0.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "data_npz[\"data_feature_min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_flag = np.tile(1, (n_ts_samples, max_ts_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(913, 120)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "data_gen_flag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting sklearn\n  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\nCollecting scikit-learn (from sklearn)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/ec/32310181e803f5d22e0dd33eb18924489b2f8d08cf5b6e116a93a6a5d1c6/scikit_learn-0.22.2.post1-cp35-cp35m-manylinux1_x86_64.whl (7.0MB)\n\u001b[K    100% |████████████████████████████████| 7.0MB 8.3MB/s \n\u001b[?25hCollecting scipy>=0.17.0 (from scikit-learn->sklearn)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\n\u001b[K    100% |████████████████████████████████| 26.0MB 2.7MB/s \n\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /data/anaconda/envs/DoppelGANger/lib/python3.5/site-packages (from scikit-learn->sklearn) (1.18.3)\nCollecting joblib>=0.11 (from scikit-learn->sklearn)\n  Using cached https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl\nBuilding wheels for collected packages: sklearn\n  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/chenhui/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\nSuccessfully built sklearn\nInstalling collected packages: scipy, joblib, scikit-learn, sklearn\nSuccessfully installed joblib-0.14.1 scikit-learn-0.22.2.post1 scipy-1.4.1 sklearn-0.0\n\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
    }
   ],
   "source": [
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(original_sales[[\"store\", \"brand\"]])\n",
    "enc.transform([[2, 1]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]])"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "store_list = original_sales[\"store\"].unique()\n",
    "brand_list = original_sales[\"brand\"].unique()\n",
    "all_store_brand = np.array([[s, b] for s, b in itertools.product(store_list, brand_list)])\n",
    "data_attribute = enc.transform(all_store_brand).toarray()\n",
    "data_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(913, 94)"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "data_attribute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "week_list = range(min_week, max_week + 1)\n",
    "d = {\"store\": store_list, \"brand\": brand_list, \"week\": week_list}\n",
    "cart = list(itertools.product(*d.values()))\n",
    "data_grid = pd.DataFrame(cart, columns=d.keys())\n",
    "original_sales_filled = pd.merge(data_grid, original_sales, how=\"left\", on=[\"store\", \"brand\", \"week\"])\n",
    "original_sales_filled = original_sales_filled.groupby([\"store\", \"brand\"]).apply(lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(110473, 19)"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "original_sales_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(106139, 19)"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "original_sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sales_filled[\"move\"] = original_sales_filled[\"logmove\"].apply(lambda x: round(math.exp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([7.16416e+05, 1.00000e+00, 1.00000e+00])"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(original_sales_filled[[\"move\", \"feat\", \"deal\"]])\n",
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.5.2 64-bit ('DoppelGANger': conda)",
   "language": "python",
   "name": "python35264bitdoppelgangerconda0d0060c0c6d34d1399cb214c1e9d6159"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}